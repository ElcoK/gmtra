{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: load all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import ast\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import YearLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from itertools import groupby\n",
    "from scipy import integrate\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('chained_assignment',None)\n",
    "\n",
    "sys.path.append(os.path.join( '..'))\n",
    "from gmtra.utils import load_config\n",
    "data_path = load_config()['paths']['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Creation of table with total length per infrastructure assets per income group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "global_countries = gpd.read_file(os.path.join(data_path,'input_data','global_countries.shp'))\n",
    "global_regions = gpd.read_file(os.path.join(data_path,'input_data','global_regions_v2.shp'))\n",
    "prot_lookup = dict(zip(global_regions['GID_2'],global_regions['prot_stand']))\n",
    "ne_countries = gpd.read_file(os.path.join(data_path,'input_data','ne_50m_admin_0_countries.shp'))\n",
    "ne_sindex = ne_countries.sindex\n",
    "\n",
    "incomegroups = pd.read_csv(os.path.join(data_path,'input_data','incomegroups_2018.csv'),index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_roads = pd.read_feather(os.path.join(data_path,'summarized','all_road_stats.ft'))\n",
    "tot_roads = tot_roads.merge(global_countries[['ISO_3digit','wbincomena']],left_on='country',right_on='ISO_3digit')\n",
    "tot_roads = tot_roads.merge(incomegroups,left_on='country',right_on='CountryCode')\n",
    "tot_len_road = pd.DataFrame(tot_roads.groupby(['GroupCode','road_type'])['length'].sum(),columns=['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_to_remove =['disused','abandoned','dismantled','preserved', 'proposed','razed', \n",
    "                 'planned','no','historical','na','not_built','abandonned', 'uncompleted', 'demolished',\n",
    "                 'abandoned_tram','construction;rail', 'rail;construction','waste_disposal','collapsed']\n",
    "\n",
    "tot_rail = pd.read_feather(os.path.join(data_path,'summarized','all_railway_stats.ft'))\n",
    "tot_rail = tot_rail.loc[~(tot_rail.infra_type.isin(rail_to_remove))]\n",
    "\n",
    "tot_rail = tot_rail.merge(global_countries[['ISO_3digit','wbincomena']],left_on='country',right_on='ISO_3digit')\n",
    "tot_rail = tot_rail.merge(incomegroups,left_on='country',right_on='CountryCode')\n",
    "\n",
    "tot_len_rail = pd.DataFrame(tot_rail.groupby('GroupCode')['length'].sum(),columns=['length'])\n",
    "tot_len_rail['road_type'] = 'Railway'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bridges_ro = pd.read_csv(os.path.join(data_path,'summarized','bridges_summary_stats.csv'))\n",
    "bridges_ro = bridges_ro.loc[~(bridges_ro.rail_type.notnull())]\n",
    "bridges_ro = bridges_ro.drop(['Unnamed: 0','Unnamed: 0.1','geometry'],axis=1)\n",
    "bridges_ro = bridges_ro.merge(incomegroups,left_on='country',right_on='CountryCode')\n",
    "bridges_ra = pd.read_csv(os.path.join(data_path,'summarized','rail_bridges_summary_stats.csv'))\n",
    "bridges_ra = bridges_ra.merge(incomegroups,left_on='country',right_on='CountryCode')\n",
    "\n",
    "tot_len_br_ro = pd.DataFrame(bridges_ro.groupby('GroupCode')['length'].sum(),columns=['length'])/1000\n",
    "tot_len_br_ro['road_type'] = 'Road Bridges'\n",
    "tot_len_br_ra = pd.DataFrame(bridges_ra.groupby('GroupCode')['length'].sum(),columns=['length'])/1000\n",
    "tot_len_br_ra['road_type'] = 'Railway Bridges'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_length = pd.concat([tot_len_road.reset_index(level=1),tot_len_rail,tot_len_br_ro,tot_len_br_ra],sort=False).reset_index().groupby(['GroupCode','road_type']).sum().unstack(1)\n",
    "all_length.to_csv('income_infra_length.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Creation of bridge fragility curve figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge_curves = pd.read_excel(os.path.join(data_path,'input_data','Costs_curves.xlsx'),sheet_name='bridge_curves',index_col=[0])\n",
    "fig,ax = plt.subplots(1,1,figsize = (8,5))\n",
    "\n",
    "color_scheme = ['#13293D','#006494','#247BA0','#1B98E0'] #['#bae4bc','#7bccc4','#43a2ca','#0868ac']\n",
    "cmap = LinearSegmentedColormap.from_list(name='continents',\n",
    "                                     colors=color_scheme)  \n",
    "\n",
    "\n",
    "bridge_curves.plot(ax=ax,linewidth=3,color='black',legend=False)\n",
    "\n",
    "ax.set_facecolor('#FAF9F9')\n",
    "ax.set_xlabel('PGA (cm/s)',fontweight='bold',fontsize=18)\n",
    "ax.set_ylabel('Fragility ratio',fontweight='bold',fontsize=18)\n",
    "ax.tick_params(axis = 'both',labelsize=14,labelcolor='black',color='black')\n",
    "\n",
    "ax.text(1425, 0.98, '1',fontweight=\"bold\",color='black', fontsize=18)\n",
    "ax.text(1425, 0.9, '2',fontweight=\"bold\",color='black', fontsize=18)\n",
    "ax.text(1425, 0.82, '3',fontweight=\"bold\",color='black', fontsize=18)\n",
    "ax.text(1425, 0.48, '4',fontweight=\"bold\",color='black', fontsize=18)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(data_path,'Figures','Bridge_fragility_curves.png'),dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Creation of flood road fragility curve figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize = (8,5))\n",
    "\n",
    "\n",
    "color_scheme = ['#13293D','#006494','#247BA0','#1B98E0'] #['#bae4bc','#7bccc4','#43a2ca','#0868ac']\n",
    "cmap = LinearSegmentedColormap.from_list(name='continents',\n",
    "                                         colors=color_scheme)  \n",
    "paved_curves = pd.read_excel(os.path.join(data_path,'input_data','Costs_curves.xlsx'),usecols=[20,21,22,23,24,25],\n",
    "                                     sheet_name='Flooding',index_col=[0],skiprows=1)\n",
    "\n",
    "paved_curves.plot(ax=ax,linewidth=3,color='black',legend=False)\n",
    "\n",
    "ax.set_facecolor('#FAF9F9')\n",
    "ax.set_xlabel('Flood Depth (in cm)',fontweight='bold',fontsize=18)\n",
    "ax.set_ylabel('Fragility ratio',fontweight='bold',fontsize=18)\n",
    "ax.tick_params(axis = 'both',labelsize=14,labelcolor='black',color='black')\n",
    "ax.set_xticks(np.arange(0,151,25))\n",
    "\n",
    "\n",
    "ax.text(152, 0.98, '1',fontweight=\"bold\",color='black', fontsize=18)\n",
    "ax.text(152, 0.78, '2',fontweight=\"bold\",color='black', fontsize=18)\n",
    "ax.text(152, 0.58, '3',fontweight=\"bold\",color='black', fontsize=18)\n",
    "ax.text(152, 0.38, '4',fontweight=\"bold\",color='black', fontsize=18)\n",
    "ax.text(152, 0.18, '5',fontweight=\"bold\",color='black', fontsize=18)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(data_path,'Figures','Flood_fragility_curves.png'),dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Creation of global liquefaction map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "\n",
    "countries = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "raster = rasterio.open(os.path.join(data_path,'hazards','Liquefaction','Global','liquefaction_v1_deg.tif'))\n",
    "\n",
    "color_scheme = ['white','#EAE2B7','#FCBF49','#F77F00','#D62828','#003049'] \n",
    "cmap = LinearSegmentedColormap.from_list(name='continents',\n",
    "                                         colors=color_scheme)  \n",
    "\n",
    "fig, ax = plt.subplots(1, 1,figsize=(20,8))\n",
    "rasterio.plot.show(raster, ax=ax,cmap=cmap)\n",
    "\n",
    "\n",
    "ax.set_ylim(-60, 90)\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "ax.patch.set_facecolor('white')\n",
    "\n",
    "legend_elements = [Patch(facecolor=color_scheme[1],label='Very Low'),\n",
    "                  Patch(facecolor=color_scheme[2],label='Low'),\n",
    "                  Patch(facecolor=color_scheme[3],label='Medium'),\n",
    "                  Patch(facecolor=color_scheme[4],label='High'),\n",
    "                   Patch(facecolor=color_scheme[5],label='Very High')]\n",
    "                   \n",
    "ax.legend(handles=legend_elements,edgecolor='#fefdfd',facecolor='#fefdfd',\n",
    "          prop={'size':16},loc=(0.01,0.1), shadow=True, fancybox=True)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(data_path,'Figures','Global_Liquefaction_Map.png'),dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Creation of file with country length values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_length_country = tot_roads.groupby(['country','road_type'])['length'].sum().unstack(1)\n",
    "rail_length_country = pd.DataFrame(tot_rail.groupby('country')['length'].sum())\n",
    "rail_length_country.columns = ['railway']\n",
    "br_ro_length_country = pd.DataFrame(bridges_ro.groupby('country')['length'].sum())/1000\n",
    "br_ro_length_country.columns = ['road_bridges']\n",
    "br_ra_length_country = pd.DataFrame(bridges_ra.groupby('country')['length'].sum())/1000\n",
    "br_ra_length_country.columns = ['railway_bridges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_file = pd.concat([road_length_country,rail_length_country,br_ro_length_country,br_ra_length_country],axis=1,sort=False)\n",
    "country_file = country_file.drop('nodata',axis=1).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_countries = gpd.read_file(os.path.join(data_path,'input_data','global_countries.shp'))\n",
    "name_lookup = dict(zip(global_countries['GID_0'],global_countries['NAME_0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_file = country_file.merge(global_countries[['ISO_3digit','NAME_0','SIDS']],left_index=True,right_on='ISO_3digit')\n",
    "country_file = country_file.groupby('NAME_0').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((country_file[['primary','secondary']].sum(axis=1)/country_file.sum(axis=1)).sort_values(ascending=False)*100).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIDS = country_file.loc[country_file.SIDS == 1]\n",
    "((SIDS[['primary','secondary']].sum(axis=1)/SIDS.sum(axis=1)).sort_values(ascending=False)*100).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
