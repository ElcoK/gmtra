{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: load all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import ast\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import YearLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from itertools import groupby\n",
    "from scipy import integrate\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('chained_assignment',None)\n",
    "\n",
    "sys.path.append(os.path.join( '..'))\n",
    "from miriam_py.utils import load_config\n",
    "data_path = load_config()['paths']['data']\n",
    "figure_path = load_config()['paths']['figures']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create functions required to make the figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_tuples(l):\n",
    "    return tuple(sum(x) for x in zip(*l))\n",
    "\n",
    "def calc_risk_total(x,hazard,RPS,events):\n",
    "    collect_risks = []\n",
    "    for y in range(7):\n",
    "        collect_risks.append(integrate.simps([x[y] for x in x[events]][::-1], x=RPS[::-1]))\n",
    "    return collect_risks\n",
    "\n",
    "def set_prot_standard(x,prot_lookup,events):\n",
    "    prot_stand = prot_lookup[x.region]\n",
    "    no_floods= [z for z in events if prot_stand > int(z.split('-')[1])]\n",
    "    for no_flood in no_floods:\n",
    "        x[no_flood] = (0,0,0,0,0,0,0)\n",
    "    return x\n",
    "\n",
    "def pluvial_design(x,hazard):\n",
    "    if x.GroupCode == 'HIC':\n",
    "        if x.road_type in ['primary','secondary']:\n",
    "            if hazard == 'PU':\n",
    "                x[['PU-5','PU-10','PU-20','PU-50']] = [(0,0,0,0,0,0,0)]*4\n",
    "            elif hazard == 'FU':\n",
    "                x[['FU-5','FU-10','FU-20','FU-50']] = [(0,0,0,0,0,0,0)]*4\n",
    "            elif hazard == 'CF':\n",
    "                x[['CF-10','CF-20','CF-50']] = [(0,0,0,0,0,0,0)]*3               \n",
    "        else:\n",
    "            if hazard == 'PU':\n",
    "                x[['PU-5','PU-10','PU-20']] = [(0,0,0,0,0,0,0)]*3\n",
    "            elif hazard == 'FU':\n",
    "                x[['FU-5','FU-10','FU-20']] = [(0,0,0,0,0,0,0)]*3\n",
    "            elif hazard == 'CF':\n",
    "                x[['CF-10','CF-20']] = [(0,0,0,0,0,0,0)]*2\n",
    "    elif x.GroupCode == 'UMC':\n",
    "        if x.road_type in ['primary','secondary']:\n",
    "            if hazard == 'PU':\n",
    "                x[['PU-5','PU-10','PU-20']] = [(0,0,0,0,0,0,0)]*3\n",
    "            elif hazard == 'FU':\n",
    "                x[['FU-5','FU-10','FU-20']] = [(0,0,0,0,0,0,0)]*3\n",
    "            elif hazard == 'CF':\n",
    "                x[['CF-10','CF-20']] = [(0,0,0,0,0,0,0)]*2\n",
    "        else:\n",
    "            if hazard == 'PU':\n",
    "                x[['PU-5','PU-10']] = [(0,0,0,0,0,0,0)]*2\n",
    "            elif hazard == 'FU':\n",
    "                x[['FU-5','FU-10']] = [(0,0,0,0,0,0,0)]*2\n",
    "            elif hazard == 'CF':\n",
    "                x[['CF-10']] = [(0,0,0,0,0,0,0)]*1\n",
    "    else:\n",
    "        if x.road_type in ['primary','secondary']:\n",
    "            if hazard == 'PU':\n",
    "                x[['PU-5','PU-10']] = [(0,0,0,0,0,0,0)]*2\n",
    "            elif hazard == 'FU':\n",
    "                x[['FU-5','FU-10']] = [(0,0,0,0,0,0,0)]*2\n",
    "            elif hazard == 'CF':\n",
    "                x[['CF-10']] = [(0,0,0,0,0,0,0)]*1\n",
    "       \n",
    "    return x\n",
    "\n",
    "def pluvial_design_rail(x,hazard):\n",
    "    if (hazard == 'PU'):\n",
    "        if  x.GroupCode == 'HIC':\n",
    "            x[['PU-5','PU-10','PU-20','PU-50']] = [(0,0,0,0,0,0,0)]*4\n",
    "        elif x.GroupCode == 'UMC':\n",
    "            x[['PU-5','PU-10','PU-20','PU-50']] = [(0,0,0,0,0,0,0)]*4\n",
    "        else:\n",
    "            x[['PU-5','PU-10','PU-20']] =[(0,0,0,0,0,0,0)]*3\n",
    "\n",
    "    if (hazard == 'FU'):\n",
    "        if  x.GroupCode == 'HIC':\n",
    "            x[['FU-5','FU-10','FU-20','FU-50']] = [(0,0,0,0,0,0,0)]*4\n",
    "        elif x.GroupCode == 'UMC':\n",
    "            x[['FU-5','FU-10','FU-20','FU-50']] = [(0,0,0,0,0,0,0)]*4\n",
    "        else:\n",
    "            x[['FU-5','FU-10','FU-20']] = [(0,0,0,0,0,0,0)]*3\n",
    "\n",
    "\n",
    "    if (hazard == 'CF'):\n",
    "        if  x.GroupCode == 'HIC':\n",
    "            x[['CF-10','CF-20','CF-50',]] =[(0,0,0,0,0,0,0)]*3\n",
    "        elif x.GroupCode == 'UMC':\n",
    "            x[['CF-10','CF-20','CF-50']] = [(0,0,0,0,0,0,0)]*3\n",
    "        else:\n",
    "            x[['CF-10','CF-20']] = [(0,0,0,0,0,0,0)]*2\n",
    "\n",
    "    return x\n",
    "\n",
    "def get_value(x,ne_sindex,ne_countries,col):\n",
    "    matches = ne_countries.loc[ne_sindex.intersection(x.centroid.bounds[:2])]\n",
    "    \n",
    "    for match in matches.iterrows():\n",
    "        if match[1].geometry.intersects(x) == True:\n",
    "            return match[1][col]\n",
    "        \n",
    "def gdp_lookup(x):\n",
    "    try:\n",
    "        return GDP_lookup[x]\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load datasets with additional information about countries and regions to create the maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "global_countries = gpd.read_file(os.path.join(data_path,'input_data','global_countries.shp'))\n",
    "global_regions = gpd.read_file(os.path.join(data_path,'input_data','global_regions_v2.shp'))\n",
    "prot_lookup = dict(zip(global_regions['GID_2'],global_regions['prot_stand']))\n",
    "ne_countries = gpd.read_file(os.path.join(data_path,'input_data','ne_50m_admin_0_countries.shp'))\n",
    "ne_sindex = ne_countries.sindex\n",
    "\n",
    "incomegroups = pd.read_csv(os.path.join(data_path,'input_data','incomegroups_2018.csv'),index_col=[0])\n",
    "global_countries['GDP'] = global_countries.geometry.apply(lambda x: get_value(x,ne_sindex,ne_countries,'GDP_MD_EST'))\n",
    "global_countries['POP'] = global_countries.geometry.apply(lambda x: get_value(x,ne_sindex,ne_countries,'POP_EST'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Specify which assets we would like to remove from railway dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_to_remove =['disused','abandoned','dismantled','preserved', 'proposed','razed', \n",
    "                 'planned','no','historical','na','not_built','abandonned', 'uncompleted', 'demolished',\n",
    "                 'abandoned_tram','construction;rail', 'rail;construction','waste_disposal','collapsed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Load all damage estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "events_FU = ['FU-5', 'FU-10', 'FU-20', 'FU-50', 'FU-75', 'FU-100', 'FU-200', 'FU-250','FU-500', 'FU-1000']\n",
    "tot_road_FU = pd.read_csv(os.path.join(data_path,'summarized','FU_road_losses.csv'),\n",
    "                          converters = dict(zip(events_FU,[ast.literal_eval]*len(events_FU))),index_col=[0]) \n",
    "tot_rail_FU = pd.read_csv(os.path.join(data_path,'summarized','FU_rail_losses.csv'),\n",
    "                          converters = dict(zip(events_FU,[ast.literal_eval]*len(events_FU))),index_col=[0]) \n",
    "print('FU loaded')\n",
    "\n",
    "events_PU = ['PU-5', 'PU-10', 'PU-20', 'PU-50', 'PU-75', 'PU-100', 'PU-200', 'PU-250', 'PU-500', 'PU-1000']\n",
    "tot_road_PU = pd.read_csv(os.path.join(data_path,'summarized','PU_road_losses.csv'),\n",
    "                          converters = dict(zip(events_PU,[ast.literal_eval]*len(events_PU))),index_col=[0]) \n",
    "tot_rail_PU = pd.read_csv(os.path.join(data_path,'summarized','PU_rail_losses.csv'),\n",
    "                          converters = dict(zip(events_PU,[ast.literal_eval]*len(events_PU))),index_col=[0]) \n",
    "print('PU loaded')\n",
    "\n",
    "events_EQ = ['EQ_rp250','EQ_rp475','EQ_rp975','EQ_rp1500','EQ_rp2475'] \n",
    "tot_road_EQ = pd.read_csv(os.path.join(data_path,'summarized','EQ_road_losses.csv'),\n",
    "                          converters = dict(zip(events_EQ,[ast.literal_eval]*len(events_EQ))),index_col=[0]) \n",
    "tot_rail_EQ = pd.read_csv(os.path.join(data_path,'summarized','EQ_rail_losses.csv'),\n",
    "                          converters = dict(zip(events_EQ,[ast.literal_eval]*len(events_EQ))),index_col=[0]) \n",
    "print('EQ loaded')\n",
    "\n",
    "events_Cyc = ['Cyc_rp50','Cyc_rp100','Cyc_rp250','Cyc_rp500','Cyc_rp1000']\n",
    "tot_road_Cyc = pd.read_csv(os.path.join(data_path,'summarized','Cyc_road_losses_uncer.csv'),\n",
    "                           converters = dict(zip(events_Cyc,[ast.literal_eval]*len(events_Cyc))))\n",
    "tot_rail_Cyc = pd.read_csv(os.path.join(data_path,'summarized','Cyc_rail_losses.csv'),\n",
    "                           converters = dict(zip(events_Cyc,[ast.literal_eval]*len(events_Cyc))))\n",
    "print('Cyc loaded')\n",
    "\n",
    "events_CF = ['CF-10', 'CF-20', 'CF-50', 'CF-100', 'CF-200', 'CF-500', 'CF-1000']\n",
    "tot_road_CF = pd.read_csv(os.path.join(data_path,'summarized','CF_road_losses.csv'),\n",
    "                          converters = dict(zip(events_CF,[ast.literal_eval]*len(events_CF))),index_col=[0])\n",
    "tot_rail_CF = pd.read_csv(os.path.join(data_path,'summarized','CF_rail_losses.csv'),\n",
    "                          converters = dict(zip(events_CF,[ast.literal_eval]*len(events_CF))),index_col=[0])\n",
    "\n",
    "print('CF loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tot_bridge_road = pd.read_csv(os.path.join(data_path,'summarized','bridge_road_risk_.csv'),index_col=[0],\n",
    "                              converters = dict(zip(['CF_risk','Cyc_risk','EQ_risk','FU_risk','PU_risk'],[ast.literal_eval]*5)))\n",
    "\n",
    "tot_bridge_road.IncomeGroup = tot_bridge_road.IncomeGroup.apply(lambda x :x.upper())\n",
    "tot_bridge_rail = pd.read_csv(os.path.join(data_path,'summarized','bridge_rail_risk_.csv'),\n",
    "                          converters = dict(zip(['CF_risk','Cyc_risk','EQ_risk','FU_risk','PU_risk'],[ast.literal_eval]*len(['CF_risk','Cyc_risk','EQ_risk','FU_risk','PU_risk']))),index_col=[0])\n",
    "\n",
    "tot_bridge_rail.IncomeGroup = tot_bridge_rail.IncomeGroup.apply(lambda x :x.upper())\n",
    "\n",
    "country_road_bridge = tot_bridge_road.loc[tot_bridge_road.road_type.isin(['primary','secondary','tertiary'])].groupby(\n",
    "    ['country'])['CF_risk','Cyc_risk','EQ_risk','FU_risk','PU_risk'].agg(sum_tuples)\n",
    "\n",
    "country_rail_bridge = tot_bridge_rail.groupby(['country'])['CF_risk','Cyc_risk','EQ_risk','FU_risk','PU_risk'].agg(sum_tuples)\n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Add additional information to the output datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_road_FU = tot_road_FU.merge(incomegroups,left_on='country',right_on='CountryCode').merge(global_countries[['ISO_3digit','wbregion']],left_on='country',right_on='ISO_3digit')\n",
    "tot_road_PU = tot_road_PU.merge(incomegroups,left_on='country',right_on='CountryCode').merge(global_countries[['ISO_3digit','wbregion']],left_on='country',right_on='ISO_3digit')\n",
    "tot_road_Cyc = tot_road_Cyc.merge(incomegroups,left_on='country',right_on='CountryCode')\n",
    "tot_road_EQ = tot_road_EQ.merge(incomegroups,left_on='country',right_on='CountryCode')\n",
    "tot_road_CF = tot_road_CF.merge(incomegroups,left_on='country',right_on='CountryCode')\n",
    "\n",
    "tot_rail_FU = tot_rail_FU.merge(incomegroups,left_on='country',right_on='CountryCode').merge(global_countries[['ISO_3digit','wbregion']],left_on='country',right_on='ISO_3digit')\n",
    "tot_rail_PU = tot_rail_PU.merge(incomegroups,left_on='country',right_on='CountryCode').merge(global_countries[['ISO_3digit','wbregion']],left_on='country',right_on='ISO_3digit')\n",
    "tot_rail_Cyc = tot_rail_Cyc.merge(incomegroups,left_on='country',right_on='CountryCode')\n",
    "tot_rail_EQ = tot_rail_EQ.merge(incomegroups,left_on='country',right_on='CountryCode')\n",
    "tot_rail_CF = tot_rail_CF.merge(incomegroups,left_on='country',right_on='CountryCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tqdm.pandas()\n",
    "tot_road_FU = tot_road_FU.progress_apply(lambda x : set_prot_standard(x,prot_lookup,events_FU),axis=1)\n",
    "tot_road_CF = tot_road_CF.progress_apply(lambda x : set_prot_standard(x,prot_lookup,events_CF),axis=1)\n",
    "\n",
    "tot_rail_FU = tot_rail_FU.progress_apply(lambda x : set_prot_standard(x,prot_lookup,events_FU),axis=1)\n",
    "tot_rail_CF = tot_rail_CF.progress_apply(lambda x : set_prot_standard(x,prot_lookup,events_CF),axis=1)\n",
    "\n",
    "tot_road_FU = tot_road_FU.progress_apply(lambda x : pluvial_design(x,'FU'),axis=1)\n",
    "tot_road_CF = tot_road_CF.progress_apply(lambda x : pluvial_design(x,'CF'),axis=1)\n",
    "tot_road_PU = tot_road_PU.progress_apply(lambda x : pluvial_design(x,'PU'),axis=1)\n",
    "tot_rail_FU = tot_rail_FU.progress_apply(lambda x : pluvial_design_rail(x,'FU'),axis=1)\n",
    "tot_rail_CF = tot_rail_CF.progress_apply(lambda x : pluvial_design_rail(x,'CF'),axis=1)\n",
    "tot_rail_PU = tot_rail_PU.progress_apply(lambda x : pluvial_design_rail(x,'PU'),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Group datasets to country level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "FU_country_stats = tot_road_FU.loc[tot_road_FU.road_type.isin(['primary','secondary','tertiary'])]\n",
    "FU_country_stats = FU_country_stats.groupby(['country'])[events_FU].agg(sum_tuples)\n",
    "\n",
    "PU_country_stats = tot_road_PU.loc[tot_road_PU.road_type.isin(['primary','secondary','tertiary'])]\n",
    "PU_country_stats = PU_country_stats.groupby(['country'])[events_PU].agg(sum_tuples)\n",
    "\n",
    "CF_country_stats = tot_road_CF.loc[tot_road_CF.road_type.isin(['primary','secondary','tertiary'])]\n",
    "CF_country_stats = CF_country_stats.groupby(['country'])[events_CF].agg(sum_tuples)\n",
    "\n",
    "EQ_country_stats = tot_road_EQ.loc[tot_road_EQ.road_type.isin(['primary','secondary','tertiary'])]\n",
    "EQ_country_stats = EQ_country_stats.groupby(['country'])[events_EQ].agg(sum_tuples)\n",
    "\n",
    "Cyc_country_stats = tot_road_Cyc.loc[tot_road_Cyc.road_type.isin(['primary','secondary','tertiary'])]\n",
    "Cyc_country_stats = Cyc_country_stats.groupby(['country'])[events_Cyc].agg(sum_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FU_country_stats_rail = tot_rail_FU.loc[~(tot_rail_FU.infra_type.isin(rail_to_remove))].groupby(\n",
    "    ['country'])[events_FU].agg(sum_tuples)\n",
    "PU_country_stats_rail = tot_rail_PU.loc[~(tot_rail_PU.infra_type.isin(rail_to_remove))].groupby(\n",
    "    ['country'])[events_PU].agg(sum_tuples)\n",
    "Cyc_country_stats_rail = tot_rail_Cyc.loc[~(tot_rail_Cyc.infra_type.isin(rail_to_remove))].groupby(\n",
    "    ['country'])[events_Cyc].agg(sum_tuples)\n",
    "EQ_country_stats_rail = tot_rail_EQ.loc[~(tot_rail_EQ.infra_type.isin(rail_to_remove))].groupby(\n",
    "    ['country'])[events_EQ].agg(sum_tuples)\n",
    "CF_country_stats_rail = tot_rail_CF.loc[~(tot_rail_CF.infra_type.isin(rail_to_remove))].groupby(\n",
    "    ['country'])[events_CF].agg(sum_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tqdm.pandas()\n",
    "RPS = [1/5,1/10,1/20,1/50,1/75,1/100,1/200,1/250,1/500,1/1000]\n",
    "country_risk_PU_road = pd.DataFrame(PU_country_stats.progress_apply(lambda x: calc_risk_total(x,'PU',RPS,events_PU),axis=1).tolist(),index=PU_country_stats.index,\n",
    "     columns=['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100'])\n",
    "country_risk_FU_road = pd.DataFrame(FU_country_stats.progress_apply(lambda x: calc_risk_total(x,'FU',RPS,events_FU),axis=1).tolist(),index=FU_country_stats.index,\n",
    "     columns=['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100'])\n",
    "country_risk_PU_rail = pd.DataFrame(PU_country_stats_rail.progress_apply(lambda x: calc_risk_total(x,'PU',RPS,events_PU),axis=1).tolist(),\n",
    "                                    index=PU_country_stats_rail.index,\n",
    "     columns=['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100'])\n",
    "country_risk_FU_rail = pd.DataFrame(FU_country_stats_rail.progress_apply(lambda x: calc_risk_total(x,'FU',RPS,events_FU),axis=1).tolist(),\n",
    "                                    index=FU_country_stats_rail.index,\n",
    "     columns=['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100'])\n",
    "\n",
    "RPS = [1/10,1/20,1/50,1/100,1/200,1/500,1/1000]\n",
    "country_risk_CF_road = pd.DataFrame(CF_country_stats.progress_apply(lambda x: calc_risk_total(x,'CF',RPS,events_CF),axis=1).tolist(),\n",
    "                       index=CF_country_stats.index,\n",
    "     columns=['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100'])\n",
    "country_risk_CF_rail = pd.DataFrame(CF_country_stats_rail.progress_apply(lambda x: calc_risk_total(x,'CF',RPS,events_CF),axis=1).tolist(),\n",
    "                       index=CF_country_stats_rail.index,\n",
    "     columns=['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100'])\n",
    "\n",
    "RPS = [1/50,1/100,1/250,1/500,1/1000]\n",
    "country_risk_EQ_road = pd.DataFrame(EQ_country_stats.progress_apply(lambda x: calc_risk_total(x,'EQ',RPS,events_EQ),axis=1).tolist(),\n",
    "                       index=EQ_country_stats.index,\n",
    "     columns=['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100'])\n",
    "country_risk_EQ_rail = pd.DataFrame(EQ_country_stats_rail.progress_apply(lambda x: calc_risk_total(x,'EQ',RPS,events_EQ),axis=1).tolist(),\n",
    "                       index=EQ_country_stats_rail.index,\n",
    "     columns=['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100'])\n",
    "\n",
    "RPS = [1/250,1/475,1/975,1/1500,1/2475]\n",
    "country_risk_Cyc_road = pd.DataFrame(Cyc_country_stats.progress_apply(lambda x: calc_risk_total(x,'Cyc',RPS,events_Cyc),axis=1).tolist(),\n",
    "                       index=Cyc_country_stats.index,\n",
    "     columns=['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100'])\n",
    "country_risk_Cyc_rail = pd.DataFrame(Cyc_country_stats_rail.progress_apply(lambda x: calc_risk_total(x,'Cyc',RPS,events_Cyc),axis=1).tolist(),\n",
    "                       index=Cyc_country_stats_rail.index,\n",
    "     columns=['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Load additional road and railway data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_roads = pd.read_feather(os.path.join(data_path,'summarized','all_road_stats.ft'))\n",
    "tot_roads = tot_roads.loc[tot_roads.road_type.isin(['primary','secondary','tertiary'])]\n",
    "tot_roads = tot_roads.merge(global_countries[['ISO_3digit','wbincomena']],left_on='country',right_on='ISO_3digit')\n",
    "tot_roads = tot_roads.merge(incomegroups,left_on='country',right_on='CountryCode')\n",
    "tot_len_road = pd.DataFrame(tot_roads.groupby('country')['length'].sum(),columns=['length'])\n",
    "lookup_length_road = dict(zip(tot_len_road.index,tot_len_road.length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_rail = pd.read_feather(os.path.join(data_path,'summarized','all_railway_stats.ft'))\n",
    "tot_rail = tot_rail.loc[~(tot_rail.infra_type.isin(rail_to_remove))]\n",
    "\n",
    "tot_rail = tot_rail.merge(global_countries[['ISO_3digit','wbincomena']],left_on='country',right_on='ISO_3digit')\n",
    "tot_rail = tot_rail.merge(incomegroups,left_on='country',right_on='CountryCode')\n",
    "tot_len_rail = pd.DataFrame(tot_rail.groupby('country')['length'].sum(),columns=['length'])\n",
    "\n",
    "tot_len = tot_len_road.add(tot_len_rail, fill_value=0)\n",
    "lookup_length = dict(zip(tot_len.index,tot_len.length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Calculate the total risk for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_br_ro = (pd.DataFrame(country_road_bridge['Cyc_risk'].apply(pd.Series)).add(\n",
    "pd.DataFrame(country_road_bridge['EQ_risk'].apply(pd.Series)), fill_value=0).add(\n",
    "pd.DataFrame(country_road_bridge['PU_risk'].apply(pd.Series)), fill_value=0).add(\n",
    "pd.DataFrame(country_road_bridge['FU_risk'].apply(pd.Series)), fill_value=0).add(\n",
    "pd.DataFrame(country_road_bridge['CF_risk'].apply(pd.Series)), fill_value=0))\n",
    "\n",
    "country_br_ro.columns = ['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']\n",
    "\n",
    "country_br_ra = (pd.DataFrame(country_rail_bridge['Cyc_risk'].apply(pd.Series)).add(\n",
    "pd.DataFrame(country_rail_bridge['EQ_risk'].apply(pd.Series)), fill_value=0).add(\n",
    "pd.DataFrame(country_rail_bridge['PU_risk'].apply(pd.Series)), fill_value=0).add(\n",
    "pd.DataFrame(country_rail_bridge['FU_risk'].apply(pd.Series)), fill_value=0).add(\n",
    "pd.DataFrame(country_rail_bridge['CF_risk'].apply(pd.Series)), fill_value=0))\n",
    "\n",
    "country_br_ra.columns = ['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_country = pd.read_csv(os.path.join(data_path,'input_data','gdp_country.csv'),encoding='iso-8859-1').fillna(0)\n",
    "GDP_lookup = dict(zip(gdp_country['Country Code'],gdp_country.max(axis=1)))\n",
    "GDP_lookup_2 = dict(zip(global_countries['GID_0'],global_countries.GDP))\n",
    "\n",
    "country_risk = country_risk_PU_road.add(country_risk_FU_road, fill_value=0).add(\n",
    "    country_risk_CF_road, fill_value=0).add(country_risk_EQ_road, fill_value=0).add(country_risk_Cyc_road, fill_value=0).add(\n",
    "    country_risk_FU_rail, fill_value=0).add(country_risk_CF_rail, fill_value=0).add(country_risk_EQ_rail, fill_value=0).add(\n",
    "    country_risk_PU_rail, fill_value=0).add(country_risk_Cyc_rail, fill_value=0).add(country_br_ro, fill_value=0).add(\n",
    "    country_br_ra, fill_value=0)\n",
    "\n",
    "country_risk = country_risk.loc[country_risk.perc_50 != 0]\n",
    "\n",
    "country_risk = country_risk.reset_index()\n",
    "country_risk['GDP'] = country_risk.country.apply(lambda x: gdp_lookup(x))\n",
    "country_risk['length'] = country_risk.country.apply(lambda x: lookup_length[x])\n",
    "\n",
    "country_risk = country_risk.loc[country_risk.perc_50 != 0]\n",
    "country_risk = country_risk.loc[country_risk.GDP != 0]\n",
    "country_risk.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Create Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_infra_value = pd.read_csv(os.path.join(data_path,'summarized','total_infrastructure_values.csv'))\n",
    "country_infra_value = total_infra_value.groupby(['country']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_lookup = dict(zip(global_countries['GID_0'],global_countries['NAME_0']))\n",
    "inc_lookup = dict(zip(incomegroups['CountryCode'],incomegroups['GroupCode'].apply(lambda x: x.upper())))\n",
    "\n",
    "color_scheme = ['#F3FFBD','#B2DBBF','#70C1B3','#247BA0'] #['#bae4bc','#7bccc4','#43a2ca','#0868ac']\n",
    "income_dict = ['LIC', 'LMC', 'UMC', 'HIC']\n",
    "color_lookup = dict(zip(income_dict,color_scheme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_risk['wbinc'] = country_risk['country'].apply(lambda x : inc_lookup[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4,figsize=(26,10))  \n",
    "fig.subplots_adjust(wspace=1)\n",
    "letters = ['A','B','C','D']\n",
    "\n",
    "for iter_,ax in enumerate(axes.flat):\n",
    "    if iter_ == 0:\n",
    "        top20 = country_risk.sort_values('perc_50',\n",
    "                                 ascending=False)[['country','perc_0','perc_20','perc_40',\n",
    "                                                   'perc_50','perc_60','perc_80','perc_100']][:20].groupby('country').sum().sort_values('perc_50',ascending=False)\n",
    "        top20 = pd.DataFrame(pd.DataFrame(top20.unstack(),columns=['Value']).reset_index(),columns=['level_0','country','Value'])\n",
    "\n",
    "        top20['Value'] = top20['Value']/1e9\n",
    "        top20['wbinc'] = top20['country'].apply(lambda x : inc_lookup[x])\n",
    "        top20['color'] = top20['wbinc'].apply(lambda x : color_lookup[x])\n",
    "        top20['country'] = top20['country'].apply(lambda x : name_lookup[x])\n",
    "        sns.boxplot(x=top20.Value,y=top20.country, showfliers=False,ax=ax,linewidth = 0.7)\n",
    "\n",
    "        ax.xaxis.set_ticks(np.arange(0,20.1,4))\n",
    "        ax.set_xlabel(xlabel='EAD in Billion USD',fontweight=\"bold\",color='black',fontsize=22) \n",
    "        ax.set_ylabel(ylabel='Country',fontweight=\"bold\",color='black',fontsize=25) #\n",
    "        ax.set_facecolor('#FAF9F9')\n",
    "        ax.spines['left'].set_color('black')\n",
    "        ax.spines['bottom'].set_color('black')        \n",
    "        ax.set_xscale(\"log\", nonposx='clip')\n",
    "        ax.set_xlim(right=20)\n",
    "        ax.xaxis.set_major_formatter(ScalarFormatter())\n",
    "        \n",
    "        for y in range(20):\n",
    "            ax.findobj(matplotlib.patches.Patch)[y].set_facecolor(top20.iloc[y]['color'])\n",
    "            ax.findobj(matplotlib.patches.Patch)[y].set_edgecolor('black')\n",
    "            \n",
    "    \n",
    "    elif iter_ == 1:\n",
    "        country_risk_gdp = country_risk.copy()\n",
    "        country_risk_gdp[['perc_0','perc_20','perc_40',\n",
    "                          'perc_50','perc_60','perc_80','perc_100']] = country_risk_gdp[['perc_0',\n",
    "                                                                                         'perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']].div(country_risk.GDP, axis=0)\n",
    "\n",
    "        top20 = country_risk_gdp.sort_values('perc_50',\n",
    "                                 ascending=False)[['country','perc_0','perc_20','perc_40',\n",
    "                                                   'perc_50','perc_60','perc_80','perc_100']][:20].groupby('country').sum().sort_values('perc_50',ascending=False)\n",
    "        top20 = pd.DataFrame(pd.DataFrame(top20.unstack(),columns=['Value']).reset_index(),columns=['level_0','country','Value'])\n",
    "\n",
    "        top20['Value'] = top20['Value']*100\n",
    "        top20['wbinc'] = top20['country'].apply(lambda x : inc_lookup[x])\n",
    "        top20['color'] = top20['wbinc'].apply(lambda x : color_lookup[x])\n",
    "        top20['country'] = top20['country'].apply(lambda x : name_lookup[x])\n",
    "\n",
    "        sns.boxplot(x=top20.Value,y=top20.country, showfliers=False,ax=ax,linewidth = 0.7)\n",
    "\n",
    "        ax.xaxis.set_ticks(np.arange(0,1.1,0.2))\n",
    "        ax.set_xlabel(xlabel='EAD in % GDP',fontweight=\"bold\",color='black',fontsize=22) \n",
    "        ax.set_ylabel(ylabel='') #\n",
    "        ax.set_facecolor('#FAF9F9')\n",
    "        ax.spines['left'].set_color('black')\n",
    "        ax.spines['bottom'].set_color('black')\n",
    "        for y in range(20):\n",
    "            ax.findobj(matplotlib.patches.Patch)[y].set_facecolor(top20.iloc[y]['color'])\n",
    "            ax.findobj(matplotlib.patches.Patch)[y].set_edgecolor('black')\n",
    "    elif iter_ == 2:\n",
    "\n",
    "        country_risk_val = country_risk.copy()\n",
    "        #country_risk_val = country_risk_val.loc[country_risk_val.country != 'MHL']\n",
    "        country_risk_val = country_risk_val.groupby('country').sum()*100\n",
    "        country_risk_val[['perc_0','perc_20','perc_40',\n",
    "                          'perc_50','perc_60','perc_80','perc_100']] = country_risk_val[['perc_0',\n",
    "                                                                                         'perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']].div(country_infra_value.infra_value, axis=0)\n",
    "        country_risk_val.reset_index(inplace=True)\n",
    "        top20 = country_risk_val.sort_values('perc_50',\n",
    "                                 ascending=False)[['country','perc_0','perc_20','perc_40',\n",
    "                                                   'perc_50','perc_60','perc_80','perc_100']][0:20].groupby('country').sum().sort_values('perc_50',ascending=False)\n",
    "        top20 = pd.DataFrame(pd.DataFrame(top20.unstack(),columns=['Value']).reset_index(),columns=['level_0','country','Value'])\n",
    "\n",
    "        top20['Value'] = top20['Value']\n",
    "        top20['wbinc'] = top20['country'].apply(lambda x : inc_lookup[x])\n",
    "        top20['color'] = top20['wbinc'].apply(lambda x : color_lookup[x])\n",
    "        top20['country'] = top20['country'].apply(lambda x : name_lookup[x])\n",
    "\n",
    "        sns.boxplot(x=top20.Value,y=top20.country, showfliers=False,ax=ax,linewidth = 0.7)\n",
    "        ax.set_facecolor('#FAF9F9')\n",
    "\n",
    "        ax.set_xlabel(xlabel='EAD in %\\nInfrastructure value',fontweight=\"bold\",color='black',fontsize=22) \n",
    "        ax.set_ylabel(ylabel='') #\n",
    "        ax.xaxis.set_ticks(np.arange(0,1.1,0.2))\n",
    "\n",
    "        ax.spines['left'].set_color('black')\n",
    "        ax.spines['bottom'].set_color('black')\n",
    "        for y in range(20):\n",
    "            ax.findobj(matplotlib.patches.Patch)[y].set_facecolor(top20.iloc[y]['color'])\n",
    "            ax.findobj(matplotlib.patches.Patch)[y].set_edgecolor('black')\n",
    "        \n",
    "    elif iter_ == 3:\n",
    "        country_risk_len = country_risk.copy()\n",
    "        country_risk_len[['perc_0','perc_20','perc_40',\n",
    "                          'perc_50','perc_60','perc_80','perc_100']] = country_risk_len[['perc_0',\n",
    "                                                                                         'perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']].div(country_risk_len.length, axis=0)\n",
    "\n",
    "        country_risk_len.reset_index(inplace=True)\n",
    "        top20 = country_risk_len.sort_values('perc_50',\n",
    "                                 ascending=False)[['country','perc_0','perc_20','perc_40',\n",
    "                                                   'perc_50','perc_60','perc_80','perc_100']][:20].groupby('country').sum().sort_values('perc_50',ascending=False)\n",
    "        top20 = pd.DataFrame(pd.DataFrame(top20.unstack(),columns=['Value']).reset_index(),columns=['level_0','country','Value'])\n",
    "\n",
    "        top20['Value'] = top20['Value']\n",
    "        top20['wbinc'] = top20['country'].apply(lambda x : inc_lookup[x])\n",
    "        top20['color'] = top20['wbinc'].apply(lambda x : color_lookup[x])\n",
    "        top20['country'] = top20['country'].apply(lambda x : name_lookup[x])\n",
    "\n",
    "        sns.boxplot(x=top20.Value,y=top20.country, showfliers=False,ax=ax,linewidth = 0.7)\n",
    "        ax.set_facecolor('#FAF9F9')\n",
    "\n",
    "        ax.set_xlabel(xlabel='EAD in USD/km',fontweight=\"bold\",color='black',fontsize=22) \n",
    "        ax.set_ylabel(ylabel='') #\n",
    "        ax.xaxis.set_ticks(np.arange(0,6001,1500))\n",
    "\n",
    "        ax.spines['left'].set_color('black')\n",
    "        ax.spines['bottom'].set_color('black')\n",
    "        for y in range(20):\n",
    "            ax.findobj(matplotlib.patches.Patch)[y].set_facecolor(top20.iloc[y]['color'])\n",
    "            ax.findobj(matplotlib.patches.Patch)[y].set_edgecolor('black')\n",
    "\n",
    "    ax.text(-1., 0.99, '{})'.format(letters[iter_]), transform=ax.transAxes,fontweight=\"bold\",color='black', fontsize=18,\n",
    "        verticalalignment='top', bbox= dict(boxstyle='round', facecolor='white', alpha=0.5,linewidth=0))\n",
    "\n",
    "    ax.tick_params(axis = 'both',labelcolor='black',color='black',labelsize=20) #\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(os.path.join(figure_path,'Fig5_losses_ranked.png'),dpi=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Creation of csv file with total country risk per hazard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQ_bridge_road = pd.DataFrame(country_road_bridge['EQ_risk'].apply(pd.Series))\n",
    "EQ_bridge_road.columns = ['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']\n",
    "EQ_bridge_rail = pd.DataFrame(country_rail_bridge['EQ_risk'].apply(pd.Series))\n",
    "EQ_bridge_rail.columns = ['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']\n",
    "EQ = pd.DataFrame(country_risk_EQ_road.add(country_risk_EQ_rail, fill_value=0).add(\n",
    "    EQ_bridge_road, fill_value=0).add(EQ_bridge_rail, fill_value=0))\n",
    "EQ.columns = pd.MultiIndex.from_product([['EQ'],EQ.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FU_bridge_road = pd.DataFrame(country_road_bridge['FU_risk'].apply(pd.Series))\n",
    "FU_bridge_road.columns = ['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']\n",
    "FU_bridge_rail = pd.DataFrame(country_rail_bridge['FU_risk'].apply(pd.Series))\n",
    "FU_bridge_rail.columns = ['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']\n",
    "FU = pd.DataFrame(country_risk_FU_road.add(country_risk_FU_rail, fill_value=0).add(FU_bridge_road, fill_value=0).add(\n",
    "    FU_bridge_rail, fill_value=0))\n",
    "FU.columns = pd.MultiIndex.from_product([['FU'],FU.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PU_bridge_road = pd.DataFrame(country_road_bridge['PU_risk'].apply(pd.Series))\n",
    "PU_bridge_road.columns = ['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']\n",
    "PU_bridge_rail = pd.DataFrame(country_rail_bridge['PU_risk'].apply(pd.Series))\n",
    "PU_bridge_rail.columns = ['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']\n",
    "PU = pd.DataFrame(country_risk_PU_road.add(country_risk_PU_rail, fill_value=0).add(PU_bridge_road, fill_value=0).add(\n",
    "    PU_bridge_rail, fill_value=0))\n",
    "PU.columns = pd.MultiIndex.from_product([['PU'],PU.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CF_bridge_road = pd.DataFrame(country_road_bridge['CF_risk'].apply(pd.Series))\n",
    "CF_bridge_road.columns = ['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']\n",
    "CF_bridge_rail = pd.DataFrame(country_rail_bridge['CF_risk'].apply(pd.Series))\n",
    "CF_bridge_rail.columns = ['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']\n",
    "CF = pd.DataFrame(country_risk_CF_road.add(country_risk_CF_rail, fill_value=0).add(CF_bridge_road, fill_value=0).add(\n",
    "    CF_bridge_rail, fill_value=0))\n",
    "CF.columns = pd.MultiIndex.from_product([['CF'],CF.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cyc_bridge_road = pd.DataFrame(country_road_bridge['Cyc_risk'].apply(pd.Series))\n",
    "Cyc_bridge_road.columns = ['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']\n",
    "Cyc_bridge_rail = pd.DataFrame(country_rail_bridge['Cyc_risk'].apply(pd.Series))\n",
    "Cyc_bridge_rail.columns = ['perc_0','perc_20','perc_40','perc_50','perc_60','perc_80','perc_100']\n",
    "Cyc = pd.DataFrame(country_risk_Cyc_road.add(country_risk_Cyc_rail, fill_value=0).add(Cyc_bridge_road, fill_value=0).add(\n",
    "    Cyc_bridge_rail, fill_value=0))\n",
    "Cyc.columns = pd.MultiIndex.from_product([['Cyc'],Cyc.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_all_hazards = pd.concat([EQ,FU,PU,CF,Cyc],sort=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_risk = country_all_hazards.sum(level=1,axis=1)\n",
    "mh_risk.columns = pd.MultiIndex.from_product([['MH'],mh_risk.columns])\n",
    "country_all_hazards = country_all_hazards.merge(mh_risk,left_index=True,right_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_all_hazards[('desc','full_name')] = country_all_hazards.index.to_series().apply(lambda x : name_lookup[x])\n",
    "country_all_hazards[('desc','wbinc')] = country_all_hazards.index.to_series().apply(lambda x : inc_lookup[x])\n",
    "country_all_hazards[('desc','GDP')] = country_all_hazards.index.to_series().apply(lambda x: gdp_lookup(x))\n",
    "country_all_hazards[('desc','length')] = country_all_hazards.index.to_series().apply(lambda x: lookup_length[x])\n",
    "country_infra_value.columns = pd.MultiIndex.from_product([['desc'],['infra_value']])\n",
    "country_all_hazards = country_all_hazards.merge(country_infra_value,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_all_hazards.reindex(['desc','MH','EQ','FU','PU','CF','Cyc'],axis=1,level=0).to_csv(os.path.join(data_path,'output_data','EAD_countries.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
